  ___                           _                ____ _     ___ 
 |_ _|_ __  ___ _ __   ___  ___| |_ ___  _ __   / ___| |   |_ _|
  | || '_ \/ __| '_ \ / _ \/ __| __/ _ \| '__| | |   | |    | | 
  | || | | \__ \ |_) |  __/ (__| || (_) | |    | |___| |___ | | 
 |___|_| |_|___/ .__/ \___|\___|\__\___/|_|     \____|_____|___|
               |_|                                              
Processing learn analysis for 14 URLs...
[1/14] ‚úì https://www.harvard.edu ‚Üí WordPress (95% confidence)
[2/14] ‚úì lamaisondaffichage.ca ‚Üí WordPress (95% confidence)
[31m[2025-07-17T01:28:03.633Z] ERROR [retry]: OpenAI Learn Analysis API call failed with non-retryable error | Data: {"error":"Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 152669 tokens. Please reduce the length of the messages."}[0m
[31m[2025-07-17T01:28:03.633Z] ERROR [learn-llm-integration]: LLM analysis failed | Data: {"url":"phased-analysis","model":"gpt-4o","apiCallDurationMs":446.26105899999675} | Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 152669 tokens. Please reduce the length of the messages.
Stack: Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 152669 tokens. Please reduce the length of the messages.
    at APIError.generate (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/error.mjs:41:20)
    at OpenAI.makeStatusError (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/core.mjs:286:25)
    at OpenAI.makeRequest (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/core.mjs:330:30)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async withRetry (file:///Users/marklummus/Documents/inspector-cli/dist/utils/retry.js:38:28)
    at async performOpenAIAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/llm-integration.js:82:26)
    at async withOpenAIResponseCache (file:///Users/marklummus/Documents/inspector-cli/dist/learn/response-cache.js:395:22)
    at async performPhase1Analysis (file:///Users/marklummus/Documents/inspector-cli/dist/utils/cms/phased-analysis.js:115:26)
    at async performPhasedAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/utils/cms/phased-analysis.js:53:30)
    at async processLearnAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:88:34)[0m
[31m[2025-07-17T01:28:03.634Z] ERROR [learn-analysis]: Learn analysis failed | Data: {"url":"guru99.com","analysisId":"learn-1752715683160-g8aijlzoo"} | Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 152669 tokens. Please reduce the length of the messages.
Stack: Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 152669 tokens. Please reduce the length of the messages.
    at processLearnAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:109:23)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async processLearnBatch (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:181:28)
    at async Command.<anonymous> (file:///Users/marklummus/Documents/inspector-cli/dist/commands/learn.js:353:29)[0m
[3/14] ‚úó guru99.com ‚Üí Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 152669 tokens. Please reduce the length of the messages.
[4/14] ‚úì outbrain.com ‚Üí WordPress (90% confidence)
[31m[2025-07-17T01:28:10.892Z] ERROR [retry]: OpenAI Learn Analysis API call failed with non-retryable error | Data: {"error":"Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 188356 tokens. Please reduce the length of the messages."}[0m
[31m[2025-07-17T01:28:10.893Z] ERROR [learn-llm-integration]: LLM analysis failed | Data: {"url":"phased-analysis","model":"gpt-4o","apiCallDurationMs":918.546242000004} | Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 188356 tokens. Please reduce the length of the messages.
Stack: Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 188356 tokens. Please reduce the length of the messages.
    at APIError.generate (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/error.mjs:41:20)
    at OpenAI.makeStatusError (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/core.mjs:286:25)
    at OpenAI.makeRequest (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/core.mjs:330:30)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async withRetry (file:///Users/marklummus/Documents/inspector-cli/dist/utils/retry.js:38:28)
    at async performOpenAIAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/llm-integration.js:82:26)
    at async withOpenAIResponseCache (file:///Users/marklummus/Documents/inspector-cli/dist/learn/response-cache.js:395:22)
    at async performPhase1Analysis (file:///Users/marklummus/Documents/inspector-cli/dist/utils/cms/phased-analysis.js:115:26)
    at async performPhasedAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/utils/cms/phased-analysis.js:53:30)
    at async processLearnAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:88:34)[0m
[31m[2025-07-17T01:28:10.893Z] ERROR [learn-analysis]: Learn analysis failed | Data: {"url":"t-mobile.com","analysisId":"learn-1752715689947-lhjkiuetp"} | Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 188356 tokens. Please reduce the length of the messages.
Stack: Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 188356 tokens. Please reduce the length of the messages.
    at processLearnAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:109:23)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async processLearnBatch (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:181:28)
    at async Command.<anonymous> (file:///Users/marklummus/Documents/inspector-cli/dist/commands/learn.js:353:29)[0m
[5/14] ‚úó t-mobile.com ‚Üí Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 188356 tokens. Please reduce the length of the messages.
[6/14] ‚úì taboola.com ‚Üí WordPress (95% confidence)
[7/14] ‚úì events.geschaeftskunden.telekom.de ‚Üí WordPress (95% confidence)
[31m[2025-07-17T01:28:38.445Z] ERROR [retry]: OpenAI Learn Analysis API call failed with non-retryable error | Data: {"error":"Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 214025 tokens. Please reduce the length of the messages."}[0m
[31m[2025-07-17T01:28:38.445Z] ERROR [learn-llm-integration]: LLM analysis failed | Data: {"url":"phased-analysis","model":"gpt-4o","apiCallDurationMs":533.3032319999911} | Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 214025 tokens. Please reduce the length of the messages.
Stack: Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 214025 tokens. Please reduce the length of the messages.
    at APIError.generate (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/error.mjs:41:20)
    at OpenAI.makeStatusError (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/core.mjs:286:25)
    at OpenAI.makeRequest (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/core.mjs:330:30)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async withRetry (file:///Users/marklummus/Documents/inspector-cli/dist/utils/retry.js:38:28)
    at async performOpenAIAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/llm-integration.js:82:26)
    at async withOpenAIResponseCache (file:///Users/marklummus/Documents/inspector-cli/dist/learn/response-cache.js:395:22)
    at async performPhase1Analysis (file:///Users/marklummus/Documents/inspector-cli/dist/utils/cms/phased-analysis.js:115:26)
    at async performPhasedAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/utils/cms/phased-analysis.js:53:30)
    at async processLearnAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:88:34)[0m
[31m[2025-07-17T01:28:38.445Z] ERROR [learn-analysis]: Learn analysis failed | Data: {"url":"wordpress.com","analysisId":"learn-1752715717883-xsvyg3k7h"} | Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 214025 tokens. Please reduce the length of the messages.
Stack: Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 214025 tokens. Please reduce the length of the messages.
    at processLearnAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:109:23)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async processLearnBatch (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:181:28)
    at async Command.<anonymous> (file:///Users/marklummus/Documents/inspector-cli/dist/commands/learn.js:353:29)[0m
[8/14] ‚úó wordpress.com ‚Üí Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 214025 tokens. Please reduce the length of the messages.
[9/14] ‚úì wordpress.org ‚Üí WordPress (95% confidence)
[31m[2025-07-17T01:28:52.838Z] ERROR [retry]: OpenAI Learn Analysis API call failed with non-retryable error | Data: {"error":"Error: 400 This model's maximum context length is 128000 tokens. However, you requested 129542 tokens (125446 in the messages, 4096 in the completion). Please reduce the length of the messages or completion."}[0m
[31m[2025-07-17T01:28:52.839Z] ERROR [learn-llm-integration]: LLM analysis failed | Data: {"url":"phased-analysis","model":"gpt-4o","apiCallDurationMs":474.6554560000077} | Error: 400 This model's maximum context length is 128000 tokens. However, you requested 129542 tokens (125446 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.
Stack: Error: 400 This model's maximum context length is 128000 tokens. However, you requested 129542 tokens (125446 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.
    at APIError.generate (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/error.mjs:41:20)
    at OpenAI.makeStatusError (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/core.mjs:286:25)
    at OpenAI.makeRequest (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/core.mjs:330:30)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async withRetry (file:///Users/marklummus/Documents/inspector-cli/dist/utils/retry.js:38:28)
    at async performOpenAIAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/llm-integration.js:82:26)
    at async withOpenAIResponseCache (file:///Users/marklummus/Documents/inspector-cli/dist/learn/response-cache.js:395:22)
    at async performPhase1Analysis (file:///Users/marklummus/Documents/inspector-cli/dist/utils/cms/phased-analysis.js:115:26)
    at async performPhasedAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/utils/cms/phased-analysis.js:53:30)
    at async processLearnAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:88:34)[0m
[31m[2025-07-17T01:28:52.839Z] ERROR [learn-analysis]: Learn analysis failed | Data: {"url":"10web.io","analysisId":"learn-1752715732337-v4fkoq4wl"} | Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, you requested 129542 tokens (125446 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.
Stack: Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, you requested 129542 tokens (125446 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.
    at processLearnAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:109:23)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async processLearnBatch (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:181:28)
    at async Command.<anonymous> (file:///Users/marklummus/Documents/inspector-cli/dist/commands/learn.js:353:29)[0m
[10/14] ‚úó 10web.io ‚Üí Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, you requested 129542 tokens (125446 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.
[31m[2025-07-17T01:28:53.427Z] ERROR [retry]: OpenAI Learn Analysis API call failed with non-retryable error | Data: {"error":"Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 170027 tokens. Please reduce the length of the messages."}[0m
[31m[2025-07-17T01:28:53.427Z] ERROR [learn-llm-integration]: LLM analysis failed | Data: {"url":"phased-analysis","model":"gpt-4o","apiCallDurationMs":561.8886490000004} | Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 170027 tokens. Please reduce the length of the messages.
Stack: Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 170027 tokens. Please reduce the length of the messages.
    at APIError.generate (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/error.mjs:41:20)
    at OpenAI.makeStatusError (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/core.mjs:286:25)
    at OpenAI.makeRequest (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/core.mjs:330:30)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async withRetry (file:///Users/marklummus/Documents/inspector-cli/dist/utils/retry.js:38:28)
    at async performOpenAIAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/llm-integration.js:82:26)
    at async withOpenAIResponseCache (file:///Users/marklummus/Documents/inspector-cli/dist/learn/response-cache.js:395:22)
    at async performPhase1Analysis (file:///Users/marklummus/Documents/inspector-cli/dist/utils/cms/phased-analysis.js:115:26)
    at async performPhasedAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/utils/cms/phased-analysis.js:53:30)
    at async processLearnAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:88:34)[0m
[31m[2025-07-17T01:28:53.428Z] ERROR [learn-analysis]: Learn analysis failed | Data: {"url":"elementor.com","analysisId":"learn-1752715732839-irlepocr8"} | Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 170027 tokens. Please reduce the length of the messages.
Stack: Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 170027 tokens. Please reduce the length of the messages.
    at processLearnAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:109:23)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async processLearnBatch (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:181:28)
    at async Command.<anonymous> (file:///Users/marklummus/Documents/inspector-cli/dist/commands/learn.js:353:29)[0m
[11/14] ‚úó elementor.com ‚Üí Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 170027 tokens. Please reduce the length of the messages.
[12/14] ‚úì jquery.com ‚Üí WordPress (95% confidence)
[13/14] ‚úì css-tricks.com ‚Üí WordPress (95% confidence)
[14/14] ‚úì https://www.branch.io/ ‚Üí WordPress (95% confidence)

Learn Analysis Results (14 URLs processed):
‚úì 9 successful, ‚úó 5 failed

Successful analyses:
- https://www.harvard.edu:
  ‚Üí Technology: WordPress (95% confidence)
  ‚Üí Key patterns: meta_generator_wordpress, url_content_wordpress, header_api_wordpress
  ‚Üí Analysis cost: 60833 tokens, $0.2889
- lamaisondaffichage.ca:
  ‚Üí Technology: WordPress (95% confidence)
  ‚Üí Key patterns: meta_generator_wordpress, url_content_wordpress, js_global_wordpress:_wpemojiSettings
  ‚Üí Analysis cost: 86746 tokens, $0.4120
- outbrain.com:
  ‚Üí Technology: WordPress (90% confidence)
  ‚Üí Key patterns: url_api_wordpress
  ‚Üí Analysis cost: 10639 tokens, $0.0505
- taboola.com:
  ‚Üí Technology: WordPress (95% confidence)
  ‚Üí Key patterns: meta_generator_wordpress, url_content_wordpress, robots_disallow_wordpress:admin
  ‚Üí Analysis cost: 69435 tokens, $0.3298
- events.geschaeftskunden.telekom.de:
  ‚Üí Technology: WordPress (95% confidence)
  ‚Üí Key patterns: url_content_wordpress, meta_generator_wordpress, header_api_wordpress
  ‚Üí Analysis cost: 25889 tokens, $0.1230
- wordpress.org:
  ‚Üí Technology: WordPress (95% confidence)
  ‚Üí Key patterns: meta_generator_wordpress, url_content_wordpress, header_x_olaf_wordpress
  ‚Üí Analysis cost: 58900 tokens, $0.2798
- jquery.com:
  ‚Üí Technology: WordPress (95% confidence)
  ‚Üí Key patterns: meta_generator_wordpress, url_content_wordpress, header_api_wordpress
  ‚Üí Analysis cost: 9447 tokens, $0.0449
- css-tricks.com:
  ‚Üí Technology: WordPress (95% confidence)
  ‚Üí Key patterns: url_content_wordpress, robots_disallow_wordpress:wp_admin, url_api_wordpress
  ‚Üí Analysis cost: 82720 tokens, $0.3929
- https://www.branch.io/:
  ‚Üí Technology: WordPress (95% confidence)
  ‚Üí Key patterns: meta_generator_wordpress, url_content_wordpress, header_api_wordpress
  ‚Üí Analysis cost: 37634 tokens, $0.1788

Failed analyses:
- guru99.com: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 152669 tokens. Please reduce the length of the messages.
- t-mobile.com: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 188356 tokens. Please reduce the length of the messages.
- wordpress.com: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 214025 tokens. Please reduce the length of the messages.
- 10web.io: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, you requested 129542 tokens (125446 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.
- elementor.com: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 170027 tokens. Please reduce the length of the messages.

Results stored in: ./data/learn/
Index file: ./data/learn/index.json

================================================================================
DETAILED ANALYSIS REPORTS
================================================================================

================================================================================
DETAILED ANALYSIS REPORT: https://www.harvard.edu
================================================================================

üéØ PLATFORM IDENTIFICATION
   Technology: WordPress
   Category: unknown
   Confidence: 95%

üîç DISCRIMINATIVE PATTERNS

üìä ANALYSIS METADATA
   Analysis ID: learn-1752715627150-7jizrn9dx
   Data Source: cached
   Token Usage: 60833 tokens
   Analysis Cost: $0.2889

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: lamaisondaffichage.ca
================================================================================

üéØ PLATFORM IDENTIFICATION
   Technology: WordPress
   Category: unknown
   Confidence: 95%

üîç DISCRIMINATIVE PATTERNS

üìä ANALYSIS METADATA
   Analysis ID: learn-1752715647421-2fu5tmavc
   Data Source: cached
   Token Usage: 86746 tokens
   Analysis Cost: $0.4120

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: outbrain.com
================================================================================

üéØ PLATFORM IDENTIFICATION
   Technology: WordPress
   Category: unknown
   Confidence: 90%

üîç DISCRIMINATIVE PATTERNS

üìä ANALYSIS METADATA
   Analysis ID: learn-1752715683634-zektt33tt
   Data Source: cached
   Token Usage: 10639 tokens
   Analysis Cost: $0.0505

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: taboola.com
================================================================================

üéØ PLATFORM IDENTIFICATION
   Technology: WordPress
   Category: unknown
   Confidence: 95%

üîç DISCRIMINATIVE PATTERNS

üìä ANALYSIS METADATA
   Analysis ID: learn-1752715690893-7scd92pai
   Data Source: cached
   Token Usage: 69435 tokens
   Analysis Cost: $0.3298

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: events.geschaeftskunden.telekom.de
================================================================================

üéØ PLATFORM IDENTIFICATION
   Technology: WordPress
   Category: unknown
   Confidence: 95%

üîç DISCRIMINATIVE PATTERNS

üìä ANALYSIS METADATA
   Analysis ID: learn-1752715703282-pu5pnozbm
   Data Source: cached
   Token Usage: 25889 tokens
   Analysis Cost: $0.1230

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: wordpress.org
================================================================================

üéØ PLATFORM IDENTIFICATION
   Technology: WordPress
   Category: unknown
   Confidence: 95%

üîç DISCRIMINATIVE PATTERNS

üìä ANALYSIS METADATA
   Analysis ID: learn-1752715718446-q9sqwcalk
   Data Source: cached
   Token Usage: 58900 tokens
   Analysis Cost: $0.2798

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: jquery.com
================================================================================

üéØ PLATFORM IDENTIFICATION
   Technology: WordPress
   Category: unknown
   Confidence: 95%

üîç DISCRIMINATIVE PATTERNS

üìä ANALYSIS METADATA
   Analysis ID: learn-1752715733428-vag128mno
   Data Source: cached
   Token Usage: 9447 tokens
   Analysis Cost: $0.0449

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: css-tricks.com
================================================================================

üéØ PLATFORM IDENTIFICATION
   Technology: WordPress
   Category: unknown
   Confidence: 95%

üîç DISCRIMINATIVE PATTERNS

üìä ANALYSIS METADATA
   Analysis ID: learn-1752715741502-3su6gyp0v
   Data Source: cached
   Token Usage: 82720 tokens
   Analysis Cost: $0.3929

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: https://www.branch.io/
================================================================================

üéØ PLATFORM IDENTIFICATION
   Technology: WordPress
   Category: unknown
   Confidence: 95%

üîç DISCRIMINATIVE PATTERNS

üìä ANALYSIS METADATA
   Analysis ID: learn-1752715762226-fo12zq2iu
   Data Source: cached
   Token Usage: 37634 tokens
   Analysis Cost: $0.1788

================================================================================

