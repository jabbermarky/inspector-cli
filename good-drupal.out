  ___                           _                ____ _     ___ 
 |_ _|_ __  ___ _ __   ___  ___| |_ ___  _ __   / ___| |   |_ _|
  | || '_ \/ __| '_ \ / _ \/ __| __/ _ \| '__| | |   | |    | | 
  | || | | \__ \ |_) |  __/ (__| || (_) | |    | |___| |___ | | 
 |___|_| |_|___/ .__/ \___|\___|\__\___/|_|     \____|_____|___|
               |_|                                              
Processing learn analysis for 16 URLs...
[1/16] ✓ https://www.uscis.gov → drupal (95% confidence)
[31m[2025-07-17T01:34:53.555Z] ERROR [retry]: OpenAI Learn Analysis API call failed with non-retryable error | Data: {"error":"Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 139728 tokens. Please reduce the length of the messages."}[0m
[31m[2025-07-17T01:34:53.555Z] ERROR [learn-llm-integration]: LLM analysis failed | Data: {"url":"phased-analysis","model":"gpt-4o","apiCallDurationMs":449.9531139999999} | Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 139728 tokens. Please reduce the length of the messages.
Stack: Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 139728 tokens. Please reduce the length of the messages.
    at APIError.generate (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/error.mjs:41:20)
    at OpenAI.makeStatusError (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/core.mjs:286:25)
    at OpenAI.makeRequest (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/core.mjs:330:30)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async withRetry (file:///Users/marklummus/Documents/inspector-cli/dist/utils/retry.js:38:28)
    at async performOpenAIAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/llm-integration.js:82:26)
    at async withOpenAIResponseCache (file:///Users/marklummus/Documents/inspector-cli/dist/learn/response-cache.js:395:22)
    at async performPhase1Analysis (file:///Users/marklummus/Documents/inspector-cli/dist/utils/cms/phased-analysis.js:115:26)
    at async performPhasedAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/utils/cms/phased-analysis.js:53:30)
    at async processLearnAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:88:34)[0m
[31m[2025-07-17T01:34:53.556Z] ERROR [learn-analysis]: Learn analysis failed | Data: {"url":"https://sahistory.org.za","analysisId":"learn-1752716093081-hf2hzu0gj"} | Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 139728 tokens. Please reduce the length of the messages.
Stack: Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 139728 tokens. Please reduce the length of the messages.
    at processLearnAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:109:23)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async processLearnBatch (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:181:28)
    at async Command.<anonymous> (file:///Users/marklummus/Documents/inspector-cli/dist/commands/learn.js:353:29)[0m
[2/16] ✗ https://sahistory.org.za → Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 139728 tokens. Please reduce the length of the messages.
[31m[2025-07-17T01:34:54.238Z] ERROR [retry]: OpenAI Learn Analysis API call failed with non-retryable error | Data: {"error":"Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 184419 tokens. Please reduce the length of the messages."}[0m
[31m[2025-07-17T01:34:54.239Z] ERROR [learn-llm-integration]: LLM analysis failed | Data: {"url":"phased-analysis","model":"gpt-4o","apiCallDurationMs":656.5368719999988} | Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 184419 tokens. Please reduce the length of the messages.
Stack: Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 184419 tokens. Please reduce the length of the messages.
    at APIError.generate (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/error.mjs:41:20)
    at OpenAI.makeStatusError (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/core.mjs:286:25)
    at OpenAI.makeRequest (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/core.mjs:330:30)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async withRetry (file:///Users/marklummus/Documents/inspector-cli/dist/utils/retry.js:38:28)
    at async performOpenAIAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/llm-integration.js:82:26)
    at async withOpenAIResponseCache (file:///Users/marklummus/Documents/inspector-cli/dist/learn/response-cache.js:395:22)
    at async performPhase1Analysis (file:///Users/marklummus/Documents/inspector-cli/dist/utils/cms/phased-analysis.js:115:26)
    at async performPhasedAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/utils/cms/phased-analysis.js:53:30)
    at async processLearnAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:88:34)[0m
[31m[2025-07-17T01:34:54.239Z] ERROR [learn-analysis]: Learn analysis failed | Data: {"url":"https://www.iefimerida.gr","analysisId":"learn-1752716093556-kio3m0wqh"} | Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 184419 tokens. Please reduce the length of the messages.
Stack: Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 184419 tokens. Please reduce the length of the messages.
    at processLearnAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:109:23)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async processLearnBatch (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:181:28)
    at async Command.<anonymous> (file:///Users/marklummus/Documents/inspector-cli/dist/commands/learn.js:353:29)[0m
[3/16] ✗ https://www.iefimerida.gr → Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 184419 tokens. Please reduce the length of the messages.
[4/16] ✓ https://www.suruga-ya.jp → drupal (95% confidence)
[5/16] ✓ https://www.un.org/en/ → drupal (95% confidence)
[6/16] ✓ https://www.yale.edu → drupal (95% confidence)
[7/16] ✓ https://www.wwe.com → drupal (95% confidence)
[8/16] ✓ https://uiowa.edu → drupal (95% confidence)
[31m[2025-07-17T01:36:09.982Z] ERROR [retry]: OpenAI Learn Analysis API call failed with non-retryable error | Data: {"error":"Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 173033 tokens. Please reduce the length of the messages."}[0m
[31m[2025-07-17T01:36:09.982Z] ERROR [learn-llm-integration]: LLM analysis failed | Data: {"url":"phased-analysis","model":"gpt-4o","apiCallDurationMs":730.9396459999989} | Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 173033 tokens. Please reduce the length of the messages.
Stack: Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 173033 tokens. Please reduce the length of the messages.
    at APIError.generate (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/error.mjs:41:20)
    at OpenAI.makeStatusError (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/core.mjs:286:25)
    at OpenAI.makeRequest (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/core.mjs:330:30)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async withRetry (file:///Users/marklummus/Documents/inspector-cli/dist/utils/retry.js:38:28)
    at async performOpenAIAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/llm-integration.js:82:26)
    at async withOpenAIResponseCache (file:///Users/marklummus/Documents/inspector-cli/dist/learn/response-cache.js:395:22)
    at async performPhase1Analysis (file:///Users/marklummus/Documents/inspector-cli/dist/utils/cms/phased-analysis.js:115:26)
    at async performPhasedAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/utils/cms/phased-analysis.js:53:30)
    at async processLearnAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:88:34)[0m
[31m[2025-07-17T01:36:09.982Z] ERROR [learn-analysis]: Learn analysis failed | Data: {"url":"https://www.alaraby.co.uk","analysisId":"learn-1752716169223-navnv98c4"} | Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 173033 tokens. Please reduce the length of the messages.
Stack: Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 173033 tokens. Please reduce the length of the messages.
    at processLearnAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:109:23)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async processLearnBatch (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:181:28)
    at async Command.<anonymous> (file:///Users/marklummus/Documents/inspector-cli/dist/commands/learn.js:353:29)[0m
[9/16] ✗ https://www.alaraby.co.uk → Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 173033 tokens. Please reduce the length of the messages.
[10/16] ✓ https://www.redhat.com/en → drupal (95% confidence)
[31m[2025-07-17T01:36:28.976Z] ERROR [retry]: OpenAI Learn Analysis API call failed with non-retryable error | Data: {"error":"Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 153849 tokens. Please reduce the length of the messages."}[0m
[31m[2025-07-17T01:36:28.976Z] ERROR [learn-llm-integration]: LLM analysis failed | Data: {"url":"phased-analysis","model":"gpt-4o","apiCallDurationMs":702.0349620000052} | Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 153849 tokens. Please reduce the length of the messages.
Stack: Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 153849 tokens. Please reduce the length of the messages.
    at APIError.generate (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/error.mjs:41:20)
    at OpenAI.makeStatusError (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/core.mjs:286:25)
    at OpenAI.makeRequest (file:///Users/marklummus/Documents/inspector-cli/node_modules/openai/core.mjs:330:30)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async withRetry (file:///Users/marklummus/Documents/inspector-cli/dist/utils/retry.js:38:28)
    at async performOpenAIAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/llm-integration.js:82:26)
    at async withOpenAIResponseCache (file:///Users/marklummus/Documents/inspector-cli/dist/learn/response-cache.js:395:22)
    at async performPhase1Analysis (file:///Users/marklummus/Documents/inspector-cli/dist/utils/cms/phased-analysis.js:115:26)
    at async performPhasedAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/utils/cms/phased-analysis.js:53:30)
    at async processLearnAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:88:34)[0m
[31m[2025-07-17T01:36:28.977Z] ERROR [learn-analysis]: Learn analysis failed | Data: {"url":"https://pantheon.io/","analysisId":"learn-1752716188253-gpy9frcv2"} | Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 153849 tokens. Please reduce the length of the messages.
Stack: Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 153849 tokens. Please reduce the length of the messages.
    at processLearnAnalysis (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:109:23)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async processLearnBatch (file:///Users/marklummus/Documents/inspector-cli/dist/learn/analysis.js:181:28)
    at async Command.<anonymous> (file:///Users/marklummus/Documents/inspector-cli/dist/commands/learn.js:353:29)[0m
[11/16] ✗ https://pantheon.io/ → Error: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 153849 tokens. Please reduce the length of the messages.
[12/16] ✓ https://www.acquia.com/ → Drupal (95% confidence)
[13/16] ✓ https://www.pfizer.com → drupal (95% confidence)
[14/16] ✓ https://commission.europa.eu/index_en → Drupal (95% confidence)
[15/16] ✓ europa.eu → drupal (95% confidence)
[16/16] ✓ https://www.defendpublichealth.org → drupal (95% confidence)

Learn Analysis Results (16 URLs processed):
✓ 12 successful, ✗ 4 failed

Successful analyses:
- https://www.uscis.gov:
  → Technology: drupal (95% confidence)
  → Key patterns: meta_generator_drupal, url_content_drupal, meta_generator_drupal
  → Analysis cost: 38063 tokens, $0.1808
- https://www.suruga-ya.jp:
  → Technology: drupal (95% confidence)
  → Key patterns: meta_generator_drupal, url_content_drupal
  → Analysis cost: 37930 tokens, $0.1802
- https://www.un.org/en/:
  → Technology: drupal (95% confidence)
  → Key patterns: meta_generator_drupal, url_content_drupal, header_cache_drupal
  → Analysis cost: 54852 tokens, $0.2605
- https://www.yale.edu:
  → Technology: drupal (95% confidence)
  → Key patterns: meta_generator_drupal, url_content_drupal, header_generator_drupal
  → Analysis cost: 40267 tokens, $0.1913
- https://www.wwe.com:
  → Technology: drupal (95% confidence)
  → Key patterns: meta_generator_drupal, header_cache_drupal, robots_disallow_drupal:modules
  → Analysis cost: 58030 tokens, $0.2756
- https://uiowa.edu:
  → Technology: drupal (95% confidence)
  → Key patterns: meta_generator_drupal, header_generator_drupal, url_content_drupal
  → Analysis cost: 45252 tokens, $0.2149
- https://www.redhat.com/en:
  → Technology: drupal (95% confidence)
  → Key patterns: meta_generator_drupal, header_cache_drupal
  → Analysis cost: 98720 tokens, $0.4689
- https://www.acquia.com/:
  → Technology: Drupal (95% confidence)
  → Key patterns: meta_generator_drupal, header_generator_drupal, url_content_drupal
  → Analysis cost: 90814 tokens, $0.4314
- https://www.pfizer.com:
  → Technology: drupal (95% confidence)
  → Key patterns: meta_generator_drupal, url_content_drupal, robots_disallow_drupal:core
  → Analysis cost: 42483 tokens, $0.2018
- https://commission.europa.eu/index_en:
  → Technology: Drupal (95% confidence)
  → Key patterns: meta_generator_drupal, header_cache_drupal, url_content_drupal
  → Analysis cost: 61155 tokens, $0.2905
- europa.eu:
  → Technology: drupal (95% confidence)
  → Key patterns: meta_generator_drupal, url_content_drupal, robots_disallow_drupal:includes
  → Analysis cost: 12697 tokens, $0.0603
- https://www.defendpublichealth.org:
  → Technology: drupal (95% confidence)
  → Key patterns: meta_generator_drupal, header_generator_drupal, url_content_drupal
  → Analysis cost: 34060 tokens, $0.1618

Failed analyses:
- https://sahistory.org.za: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 139728 tokens. Please reduce the length of the messages.
- https://www.iefimerida.gr: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 184419 tokens. Please reduce the length of the messages.
- https://www.alaraby.co.uk: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 173033 tokens. Please reduce the length of the messages.
- https://pantheon.io/: Phased analysis failed: Phase 1 failed: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 153849 tokens. Please reduce the length of the messages.

Results stored in: ./data/learn/
Index file: ./data/learn/index.json

================================================================================
DETAILED ANALYSIS REPORTS
================================================================================

================================================================================
DETAILED ANALYSIS REPORT: https://www.uscis.gov
================================================================================

🎯 PLATFORM IDENTIFICATION
   Technology: drupal
   Category: unknown
   Confidence: 95%

🔍 DISCRIMINATIVE PATTERNS

📊 ANALYSIS METADATA
   Analysis ID: learn-1752716081031-jaukxboo2
   Data Source: cached
   Token Usage: 38063 tokens
   Analysis Cost: $0.1808

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: https://www.suruga-ya.jp
================================================================================

🎯 PLATFORM IDENTIFICATION
   Technology: drupal
   Category: unknown
   Confidence: 95%

🔍 DISCRIMINATIVE PATTERNS

📊 ANALYSIS METADATA
   Analysis ID: learn-1752716094239-ty1igbyjm
   Data Source: cached
   Token Usage: 37930 tokens
   Analysis Cost: $0.1802

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: https://www.un.org/en/
================================================================================

🎯 PLATFORM IDENTIFICATION
   Technology: drupal
   Category: unknown
   Confidence: 95%

🔍 DISCRIMINATIVE PATTERNS

📊 ANALYSIS METADATA
   Analysis ID: learn-1752716105418-6yl7s8p1x
   Data Source: cached
   Token Usage: 54852 tokens
   Analysis Cost: $0.2605

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: https://www.yale.edu
================================================================================

🎯 PLATFORM IDENTIFICATION
   Technology: drupal
   Category: unknown
   Confidence: 95%

🔍 DISCRIMINATIVE PATTERNS

📊 ANALYSIS METADATA
   Analysis ID: learn-1752716123856-463gskvzh
   Data Source: cached
   Token Usage: 40267 tokens
   Analysis Cost: $0.1913

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: https://www.wwe.com
================================================================================

🎯 PLATFORM IDENTIFICATION
   Technology: drupal
   Category: unknown
   Confidence: 95%

🔍 DISCRIMINATIVE PATTERNS

📊 ANALYSIS METADATA
   Analysis ID: learn-1752716141584-jkiy5nzad
   Data Source: cached
   Token Usage: 58030 tokens
   Analysis Cost: $0.2756

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: https://uiowa.edu
================================================================================

🎯 PLATFORM IDENTIFICATION
   Technology: drupal
   Category: unknown
   Confidence: 95%

🔍 DISCRIMINATIVE PATTERNS

📊 ANALYSIS METADATA
   Analysis ID: learn-1752716156584-f6ojhxn4k
   Data Source: cached
   Token Usage: 45252 tokens
   Analysis Cost: $0.2149

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: https://www.redhat.com/en
================================================================================

🎯 PLATFORM IDENTIFICATION
   Technology: drupal
   Category: unknown
   Confidence: 95%

🔍 DISCRIMINATIVE PATTERNS

📊 ANALYSIS METADATA
   Analysis ID: learn-1752716169983-fj2dbsh68
   Data Source: cached
   Token Usage: 98720 tokens
   Analysis Cost: $0.4689

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: https://www.acquia.com/
================================================================================

🎯 PLATFORM IDENTIFICATION
   Technology: Drupal
   Category: unknown
   Confidence: 95%

🔍 DISCRIMINATIVE PATTERNS

📊 ANALYSIS METADATA
   Analysis ID: learn-1752716188977-j5sfljm6n
   Data Source: cached
   Token Usage: 90814 tokens
   Analysis Cost: $0.4314

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: https://www.pfizer.com
================================================================================

🎯 PLATFORM IDENTIFICATION
   Technology: drupal
   Category: unknown
   Confidence: 95%

🔍 DISCRIMINATIVE PATTERNS

📊 ANALYSIS METADATA
   Analysis ID: learn-1752716210696-nev63yzn7
   Data Source: cached
   Token Usage: 42483 tokens
   Analysis Cost: $0.2018

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: https://commission.europa.eu/index_en
================================================================================

🎯 PLATFORM IDENTIFICATION
   Technology: Drupal
   Category: unknown
   Confidence: 95%

🔍 DISCRIMINATIVE PATTERNS

📊 ANALYSIS METADATA
   Analysis ID: learn-1752716228327-mkvy4r8wk
   Data Source: cached
   Token Usage: 61155 tokens
   Analysis Cost: $0.2905

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: europa.eu
================================================================================

🎯 PLATFORM IDENTIFICATION
   Technology: drupal
   Category: unknown
   Confidence: 95%

🔍 DISCRIMINATIVE PATTERNS

📊 ANALYSIS METADATA
   Analysis ID: learn-1752716249549-7zqk8r65r
   Data Source: cached
   Token Usage: 12697 tokens
   Analysis Cost: $0.0603

================================================================================


================================================================================
DETAILED ANALYSIS REPORT: https://www.defendpublichealth.org
================================================================================

🎯 PLATFORM IDENTIFICATION
   Technology: drupal
   Category: unknown
   Confidence: 95%

🔍 DISCRIMINATIVE PATTERNS

📊 ANALYSIS METADATA
   Analysis ID: learn-1752716272944-r3myzjp1z
   Data Source: cached
   Token Usage: 34060 tokens
   Analysis Cost: $0.1618

================================================================================

